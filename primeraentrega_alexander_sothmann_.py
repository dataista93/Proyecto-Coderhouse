# -*- coding: utf-8 -*-
"""PrimeraEntrega_Alexander_Sothmann_.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bHn6cpzxQQsB8a22wk4_tdVaNQbXt06t

####**TITULO:** Evaluación de implemetanción de sistema CRM para la atención a la ciudadania. 


####**INDICE** 
1. [Introducción](#id1)
2. [Limipieza y exploración del datasets](#id2)
3. [Estadística descriptiva](#id3)
4. [Estado de la demanda al primer año de implementación](#id4)
5. [Calidad del servicio segun observaciones](#id5)
6. [Analisis cuantitativo de las observaciones](#id6)
7. [Auditoria de casos](#id7)
8. [Resultados finales y propuesta](#id8)

## **1. Introducción**<a name="id1"></a>

El siguente trababajo se propone evaluar el proceso de implementación del sistema CRM de Wise CX al SENASA a inicios del año 2022, para ofrecer a la ciudadania canales anteción mediante correo, chat online y Whatsapp. Este sistema permite la multicanalidad y omnicanlidad centrada en un solo sistema y a su vez permite herramientas como asistentes virtuales o chat bot. 

La evaluación propuesta no aborda cuestiones tecnicas del sistema, sino que se orienta a la calidad del servicio brindado y la respuesa a las demanda generada en la ciudadadania, quien ya esta habituada a comunciarse por estos medios. Algunas de las hipotesis o preguntas orientadoras son: 

**Pregunta fundamental**:

- ¿El nuevo servicio de atención era necesario?¿Cuál era su demanda real?

**Preguntas derivadas** (en caso de confirmarse la demanda):

- ¿Cuales son las consultas frecuentes? 
- ¿Cuál es la capacidad operativa de respuesta? 
- En relación a las principales variables de tiempo, tipo de consulta y extensión de la conversación ¿Que nivel de satifacción se detecta y cual es la calidad del servicio? 
- ¿Qué indicadores se pueden plantear para el 2023 para monitorear la calidad del servicio? 

El conjunto de datos corresponde a los datos exportados del sistema de reportes que genera Wise CX de todos los casos recepcionados para su atención primaria.

**Fuente y descripción de variables** - dato no publico,obtención propia del sistema CRM de Wise CX utilizado para la atención al publico por chat,correo y WhatsApp.

**Contexto comercial y analítico** - Las variables potenciales involucradas son las que permiten un analisis de la calidad recibida en la atención. Desde tiempo de gestión, encuestas, tipificaciones categoricas de los casos, etc. Todo esto permite automatizar el analisis y la deteccion de no conformidades. Es decir, no solo un analisis descriptivo, sino que tambien un control de calidad para emitir informes automatizables. 

**Contexto de implementación** - El sistema se aplico de forma reciente, por esto la serie temporal tiene como rango 1 año. Desde el cual tiene vigencia. Por esto es importante orientar el analisis de los datos para brindar un estado de implementación 

Finalemte, para llevar a cabo el trabajo se utilizara como recurso las librerias pertenecientes al lengaje de programación Phyton orientado a la ciencia de datos. Estas se exponen a continuación y luego se importan los datos:
"""

# Commented out IPython magic to ensure Python compatibility.
#Importación de datos

from google.colab import drive

# Operaciones matematicas, manipulación y transformación de datos

from datetime import date, time, datetime
import numpy as np
import pandas as pd
import statistics as stats

# Visualización de graficos

import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
import seaborn as sb
import plotly as py
import plotly.graph_objs as go
plt.style.use('fivethirtyeight')
mpl.style.use('bmh')
# %matplotlib inline
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
plt.rcParams['figure.figsize'] = (16, 9)
plt.style.use('ggplot')

# Machine Learning

from sklearn import linear_model
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt 
import warnings
warnings.filterwarnings("ignore")
from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score

"""
Me concecto a mi Google Drive y importo el archivo Excel separado cada hoja de calculo que lo compone.

"""

drive.mount('/content/drive')

df_casos = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Actividades /Datos/Casos Wise/Casos_CRM_definitivo.xlsx',sheet_name=1)

df_encuestas = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Actividades /Datos/Casos Wise/Casos_CRM_definitivo.xlsx',sheet_name=0)

"""##**2. Limipieza y exploración del datasets**<a name="id2"></a>

##**Limpieza del datasets**

El dataset a limpiar, para poder realizar la descripción de las variables de interés y la estadística descriptiva, es el de **df_casos**. En una primera instancias se puede ver columnas con nombres poco intuitivos para el analisis, como a su vez columnas con muchos valores nulos, lo cual indica que no hay datos significativos para su analisis. En el caso de **df_encuestas** esto no sucede. Tambien se transformaran datos de tiempo que estan en segundos y al ser valores muy grandes se convertiran a minutos. 

Como elemento ajenos al dataset original se crearan columnas que permitran el control de calidad planteado como objetivo del trabajo. Es decir, se automatizara el control de etiquetado como "observado" aquellas conversaciones donde la ciudadania abandona la conversación. A su vez se crearan columnas para poder confirmar si el caso se da por perdido sin posibilidad de recuperación para resolver la consulta sin respuesta. 

Otra transformación es la tificación de casos segun un filtrado de texto de aquellas conversaciones que no se tengan clasificadas. 

A su vez, para no copiar y pegar diferentes filtros o condiciones en los diferentes graficos. Esto se realizara en una sola sección de limpieza.

El resultado final sera el dataset **df_casos_final**, al cual luego solo se manipulara para realizar graficos y calculos. Pero la base de los datos siempre sera la misma. 

Las variables a obtener son las siguentes:
                                                              
- **Numero unico de caso**: Numero unico de conversación.Es decir un identificador unico o ID.
- **Canal**: La multicanalidad de la plataforma permite 3 tipos de conversaciones.Estas son chat en linea,correo y WhatsApp. 
- **Primer mensaje**: La primera oración que aparece cuando la persona conversa. 
- **Caso: Descripción**:Descripción de texto libre que el operador puede redactar para agregar información.
- **Usuario**:Indica que si la conversación fue atendida por el asistente virtual o mediante un operador humano. 
- **Fecha de creación**:Fecha y hora en que se creo la conversación.
- **Fecha primer cambio**:Fecha y hora en que hubo algun cmbio en la trazabilidad de la conversación.
- **Fecha asignación agente**: Fecha y hora en que se le asigno al operador una conversación.
- **Fecha de resolución**: Fecha y hora en que se cambio el estado de la conversación a resuelta.
- **Etiquetas**: Listado de sub-categorias pre-establecidas para agregar detalle a las tipificaciones.                                              - **Tipo**: Listado de categorias mas generales pre-establecidad para tipificar conversaciones.
- **Fecha primera respuesta**: Fecha y hora del primer mensaje enviado por el operador (no asistente virtual).
- **Fecha ultima respuesta**: Fecha y hora del ultimo mensaje enviado por el operador (no asistente virtual)      
-  **Cantidad de mensajes por conversación**: Cantidad de mensajes que tuvo la conversación. Ya sea con el asistente virtual o con el operador.                           
- **Correo ciudadano/a**: Correo que declara la persona al iniciar una conversación. Siempre es un dato obligatorio, proque permite la trazabilidad de conversaciones que tuvo.
- **Tiempo de espera asignación (en min)**: La cantidad total de minutos que espero la persona en ser atendido.Ya sea por el asistente virtual o por el operador luego. 
- **Tiempo de espera primera respuesta (en min)**: La cantidad total de minutos que que la persona espero entre que se asigno la conversación al operador y este le escribio el primer mensaje. 
- **Control de conversaciones**: Clasificación de la conversación como observada, porque la persona abandono la conversación porque disconformidad o porque nunca lo atendieron. Esto permite realizar su seguimiento y plantear un indicadro de recuperación o perdida de personas contactadas. 
- **Envio Correo**: Indica si la persona envio un correo. Esto se creo para saber si una persona que se comunico al chat o WhatsApp. Pero luego se clasifico como observado, se volvio a comunicar por correo (Ya que en estos casos siempre hay una automatización y plantilla a enviar por correo para que se comunique). 
- **Envio encuesta**: Indica si la persona envio una encuesta. Esto se creo para saber si una persona que se comunico al chat o WhatsApp. Pero luego se clasifico como observado, se volvio a comunicar por encuesta (Ya que en estos casos siempre hay una automatización y plantilla a enviar por correo para que se comunique). 
- **Realizo re-consulta**: Indica si la persona se volvio a comunicar mas de una vez. Esto se creo para saber si una persona que se comunico al chat o WhatsApp. Pero luego se clasifico como observado, se volvio a comunicar.
- **Número de serie**:Numero unico de encuesta.Es decir un identificador unico o ID.
- **Fecha de envio**: Fecha y hora en que envio la encuesta.      
- **Correo electrónico**: Unico dato de identificación requerido y que permite una retroalimentación en caso de queja.                        
- **¿Cuál fue tu canal de contacto con nosotros?**:Ademas de los canales incorporados a Wise CX esta el presencial y el telefonico.   
- **¿Cuál es tu opinión sobre la atención recibida?**: Respuesta categorica de "Debe mejorar significativamente" a "excelente" como ambos extremos.        
- **¿Cuál es tu opinión sobre la atención recibida?**:Respuesta categorica de "Debe mejorar significativamente" a "excelente" como ambos extremos.  
- **¿Obtuviste la información que buscabas?**: Respuesta categorica de "si" o "no". 
- **¿Tenés otros comentarios, sugerencias u observaciones sobre el servicio recibido?**: Campo libre de texto para dejar un breve comentario y en caso de disconformidad se genera una retroalimentación para continuar el caso. 

Para obtener estas variables se realizo la siguente limpieza:
"""

"""  1) Eliminar y renombrar columnas """ 

df_casos_limpio1 = df_casos.drop(columns = ['Cliente Nombre','Estado','Site','Equipo','Caso: Sentiment','Caso: Canal/Cuenta','Caso: Last NPS','Bot Active','Bot Attended','Bot Resolved','Caso: AHT','Caso: Fecha Vto.','Caso: Fecha Cierre','Caso: Prioridad','Caso: SLA','Caso: Last Follow','Caso: Empresa','Cliente: Empresa','Cliente: Rol','Cliente: Teléfono','Cliente: ID Personal','Cliente: Domicilio','Cliente: Ciudad','Cliente: País','Cliente: Facebook','Cliente: Twitter','Cliente: Instagram','Empresa: Nombre','Empresa: Email','Empresa: Teléfono','Empresa: ID'], axis=1)
df_casos_limpio1.rename(columns = {'Caso: Canal': 'Canal'}, inplace = True)
df_casos_limpio1.rename(columns = {'#': 'Numero unico de caso'}, inplace = True)
df_casos_limpio1.rename(columns = {'subject': 'Primer mensaje'}, inplace = True)
df_casos_limpio1.rename(columns = {'Caso: Creado': 'Fecha de creación'}, inplace = True)
df_casos_limpio1.rename(columns = {'Caso: Actualizado': 'Fecha primer cambio'}, inplace = True)
df_casos_limpio1.rename(columns = {'Caso: Asignación': 'Fecha asignación agente'}, inplace = True)
df_casos_limpio1.rename(columns = {'Caso: Resuelta': 'Fecha de resolución'}, inplace = True)
df_casos_limpio1.rename(columns = {'Caso: Etiquetas': 'Etiquetas'}, inplace = True)
df_casos_limpio1.rename(columns = {'Caso: WT': 'Tiempo de espera asignación (en min)'}, inplace = True)
df_casos_limpio1.rename(columns = {'Caso: HT': 'Tiempo de espera primera respuesta (en min)'}, inplace = True)
df_casos_limpio1.rename(columns = {'Caso: RT': 'Tiempo de resolución del caso (en min)'}, inplace = True)
df_casos_limpio1.rename(columns = {'Caso: Primer Resp.': 'Fecha primera respuesta'}, inplace = True)
df_casos_limpio1.rename(columns = {'Caso: Última Resp.': 'Fecha ultima respuesta'}, inplace = True)
df_casos_limpio1.rename(columns = {'Caso: Mensajes': 'Cantidad de palabras por conversación'}, inplace = True)
df_casos_limpio1.rename(columns = {'Cliente: Email': 'Correo ciudadano/a'}, inplace = True)


"""  2) Filtramos y renombramos valores de registros """ 

df_casos_limpio1 = df_casos_limpio1.loc[df_casos_limpio1['Fecha de creación'].between('2022-01-01 01:01:49',
                                                                                      '2022-12-31 23:59:00')]
df_casos_limpio1.loc[df_casos_limpio1['Canal'] == 'WhatsApp Saliente', "Canal"] = "WhatsApp"
df_casos_limpio1.loc[df_casos_limpio1['Usuario'] == 'Asistente Virtual 2', "Usuario"] = "Asistente Virtual"
df_casos_limpio1 = df_casos_limpio1.replace('Asistente Virtual ',"Asistente Virtual") #Quedaba con un espacio y los tomaba como diferentes

""" 3) Las columnas de tiempo estan en segundos, se convierten en minutos 
para achicar los valores """ 

df_casos_limpio1 = pd.concat([df_casos_limpio1[['Numero unico de caso','Canal',
                                                'Primer mensaje','Caso: Descripción',
                                                'Usuario','Fecha de creación','Fecha primer cambio',
                                                'Fecha asignación agente','Fecha de resolución','Etiquetas',
                                                'Tipo','Fecha primera respuesta','Fecha ultima respuesta',
                                                'Cantidad de palabras por conversación','Correo ciudadano/a']] 
                              , round(df_casos_limpio1.loc[:,['Tiempo de espera asignación (en min)',
                                                              'Tiempo de espera primera respuesta (en min)',
                                                              'Tiempo de resolución del caso (en min)']]/60)], axis=1,)

""" 4) Se eliminan las filas de correos que no son casos reales,porque son correos 
internos o del proveedor.Se crea y aplica filtro. """

df_correos = df_casos_limpio1[['Correo ciudadano/a','Fecha de creación']] 
df_correos = df_correos[df_correos['Correo ciudadano/a'].str.contains(
    '@senasa.gob.ar|@wisecx.com.gob.ar', regex=True, na=True)]
lista_correos = df_correos['Correo ciudadano/a'].unique().tolist()

lista_correos.remove('mesadeayuda@senasa.gob.ar')
lista_correos.remove('mesageneral@senasa.gob.ar')
lista_correos.remove('denuncias@senasa.gob.ar')

valores_filtrados = lista_correos 

df_casos_limpio1 = df_casos_limpio1[~df_casos_limpio1['Correo ciudadano/a'].isin(valores_filtrados)]

""" 5) Filtro de la variedad de usuarios solo en 3 categorias, que sea bot, operados o sin asignar """ 

filtro_usuario = df_casos_limpio1['Usuario'].unique().tolist()
filtro_usuario.remove('[Sin Asignar]')
filtro_usuario.remove('Asistente Virtual')
df_casos_limpio1 = df_casos_limpio1.replace(filtro_usuario,"Operador") 


""" 6) Creo mediante una funcion con condicionales 2 columnas para control de calidad 
(para canal chat y WhatsApp)  y hago un LEFT JOIN con el data set de encuentas, que tiene un origen de datos 
diferente y por eso no sale del mismo reporte. """

def controldecalidad(x):
    if x['Usuario'] == '[Sin Asignar]' and x['Canal']!='Email Entrante':
        return 'Observado'
    elif x['Tipo'] == 'NO RECIBIDO' and x['Canal']!='Email Entrante':
        return 'Observado'
    elif x['Tipo'] == 'CHAT SUSPENDIDO' and x['Canal']!='Email Entrante':
        return 'Observado'
    elif x['Tipo'] == 'NO INFORMA TEMA' and x['Canal']!='Email Entrante':
        return 'Observado'
    elif x['Fecha primera respuesta'] is pd.NaT and x['Canal']!='Email Entrante':
        return 'Observado'
    else:
         return 'No observado' 

df_casos_limpio1['Control de conversaciones'] = df_casos_limpio1.apply(controldecalidad, axis=1) #AYUDA MEMORIA - Si se una axis=0 la iteración la realiza sobre todas las filas.  


# 7) Limipieza de datos de la columna "Tipo" donde hay muchas conversaciones sin tipificar

df_casos_limpio1 = df_casos_limpio1.replace('[Sin Tipo]','SIN TIPO')
df_casos_limpio1 = df_casos_limpio1.replace('DATO ABIERTO','INFO. PÚBLICA')
df_casos_limpio1 = df_casos_limpio1.replace('Bot','SIN TIPO')
df_casos_limpio1 = df_casos_limpio1.replace('Teléfono','SIN TIPO')
df_casos_limpio1['Tipo'].replace('Chat ','SIN TIPO')
df_casos_limpio1 = df_casos_limpio1.replace('ENVÍO CORREO ELECTRÓNICO','SIN TIPO')
df_casos_limpio1 = df_casos_limpio1.replace('Consultas/Solicitudes -> Extra Senasa','EXTRA SENASA')
df_casos_limpio1 = df_casos_limpio1.replace('Consultas/Solicitudes -> Consulta bibliográfica y/o normativa','CONSULTA NORMATIVA/BIBLIOGRAFICA')
df_casos_limpio1 = df_casos_limpio1.replace('Consultas/Solicitudes -> Consulta ciudadana','SIN TIPO')
df_casos_limpio1 = df_casos_limpio1.replace('Consultas/Solicitudes -> Trámites','SIN TIPO')
df_casos_limpio1 = df_casos_limpio1.replace('PROD. FITOSANITARIOS','AGROQUÍMICOS')
df_casos_limpio1 = df_casos_limpio1.replace('ALIMENTOS PARA ANIMALES','APROBACION DE PRODUCTOS')

# 8) Se recuperan tipificaciones de conversación a partir de la columna de "Caso: Descripción"

df_casos_limpio1['Caso: Descripción'] = df_casos_limpio1['Caso: Descripción'].fillna('SIN DESCRIPCIÓN') #Reemplazo los NaN por esa sola palabra
df_casos_limpio1['Caso: Descripción'] = df_casos_limpio1['Caso: Descripción'].str.upper()

"""
Esta función toma una columna y en refencia a una lista de valores reemplaza 
en la columna los valores por uno que yo le indique.
"""
def reemplazar_valores(df, columna, valores_lista, palabra_reemplazo): 
    df[columna] = df[columna].replace(valores_lista, palabra_reemplazo)
    return df

""" Creamos las listas para reemplazar luego en la columana. Se usa como 
criterio tratar de recuperar el mayor de conversaciones mas consultadas o mas
sensible para el Organismo de acuerdo a sus consultar frecuentes. Por ejemplo,
viajeros con mascotas o RENSPA"""

lista_mascotas = df_casos_limpio1[df_casos_limpio1['Caso: Descripción'].str.contains(
    'MASCOT|PERRO|LAZARETO|MSCOTA|TURNO|CVI|AUTOGEST|DCEA|VACUNA|AEROPAR|EZEI',regex=True, na=True)]
lista_mascotas = lista_mascotas ['Caso: Descripción'].tolist()

lista_capacitacion = df_casos_limpio1[df_casos_limpio1['Caso: Descripción'].str.contains(
    'ACREDI|CURSO|CAPACITA',regex=True, na=True)]
lista_capacitacion  = lista_capacitacion['Caso: Descripción'].tolist()

lista_trazabilidad = df_casos_limpio1[df_casos_limpio1['Caso: Descripción'].str.contains(
    'TRAZA',regex=True, na=True)]
lista_trazabilidad = lista_trazabilidad['Caso: Descripción'].tolist()

lista_aprobaciondeproductos = df_casos_limpio1[df_casos_limpio1['Caso: Descripción'].str.contains(
     'ALIMENTO|ENVASE|ADITI|ORGANIC|CRAA|COADYUV',regex=True, na=True)]
lista_aprobaciondeproductos = lista_aprobaciondeproductos['Caso: Descripción'].tolist()

lista_habilistaciondetransporte = df_casos_limpio1[df_casos_limpio1['Caso: Descripción'].str.contains(
     'TRANSPOR',regex=True, na=True)]
lista_habilistaciondetransporte = lista_habilistaciondetransporte['Caso: Descripción'].tolist()

lista_dtv = df_casos_limpio1[df_casos_limpio1['Caso: Descripción'].str.contains(
     'DTV',regex=True, na=True)]
lista_dtv  = lista_dtv['Caso: Descripción'].tolist()

lista_dte = df_casos_limpio1[df_casos_limpio1['Caso: Descripción'].str.contains(
     'DTE|CARAVAN|ANIMALES VIVOS',regex=True, na=True)]
lista_dte = lista_dte ['Caso: Descripción'].tolist()

lista_renspa = df_casos_limpio1[df_casos_limpio1['Caso: Descripción'].str.contains(
     'RENSPA|VIVER|AGRICULTURA FAMI|AFTOSA|AVE|APÍCO|APICO|APICU',regex=True, na=True)]
lista_renspa  = lista_renspa ['Caso: Descripción'].tolist()

lista_afidi = df_casos_limpio1[df_casos_limpio1['Caso: Descripción'].str.contains(
     'AFIDI',regex=True, na=True)]
lista_afidi  = lista_afidi['Caso: Descripción'].tolist()

lista_laboratorio = df_casos_limpio1[df_casos_limpio1['Caso: Descripción'].str.contains(
     'LABORAT',regex=True, na=True)]
lista_laboratorio = lista_laboratorio['Caso: Descripción'].tolist()

df_casos_limpio1 = reemplazar_valores(df_casos_limpio1, 'Caso: Descripción', lista_mascotas, 'TRASLADO MASCOTAS')
df_casos_limpio1 = reemplazar_valores(df_casos_limpio1, 'Caso: Descripción', lista_capacitacion, 'CAPACITACION')
df_casos_limpio1 = reemplazar_valores(df_casos_limpio1, 'Caso: Descripción', lista_trazabilidad, 'TRAZABILIDAD')
df_casos_limpio1 = reemplazar_valores(df_casos_limpio1, 'Caso: Descripción', lista_aprobaciondeproductos, 'APROBACION DE PRODUCTOS')
df_casos_limpio1 = reemplazar_valores(df_casos_limpio1, 'Caso: Descripción', lista_habilistaciondetransporte, 'HABILITACION DE TRANSPORTE')
df_casos_limpio1 = reemplazar_valores(df_casos_limpio1, 'Caso: Descripción', lista_dtv, 'DTV')
df_casos_limpio1 = reemplazar_valores(df_casos_limpio1, 'Caso: Descripción', lista_dte, 'DTE')
df_casos_limpio1 = reemplazar_valores(df_casos_limpio1, 'Caso: Descripción', lista_renspa, 'RENSPA')
df_casos_limpio1 = reemplazar_valores(df_casos_limpio1, 'Caso: Descripción', lista_afidi, 'AFIDI')
df_casos_limpio1 = reemplazar_valores(df_casos_limpio1, 'Caso: Descripción', lista_laboratorio , 'LABORATORIO')

""" Reemplazamos los valores modificados en la columna "Descripción: Caso" en la 
columna "Tipo" filtrando en aquellos registros que sean "SIN TIPO" """ 

df_casos_limpio1.loc[df_casos_limpio1['Tipo'] == 'SIN TIPO', 'Caso: Descripción'] = df_casos_limpio1.loc[df_casos_limpio1['Tipo'] == 'SIN TIPO', 'Tipo']

""" 9) Se realizan multiples joins o relaciónes:

El principal join o relación es con la otra hoja del archivo Excel donde estan 
las encuestas. Luego de los mismos datos del reporte de conversaciones se filtran 
3 data frame a los fines de control recuperación de aquellas conversaciones que
se observaron por alguna problematica:

1- merged_df1: La primera son todo/a ciudadana/o que envio un correo ademas 
del chat o whatsapp
observado.

2- merged_df2: La segunda son todo/a ciudadana/o que envio una encuesta ademas 
del chat o whatsapp observado.

3- merged_df3: La segunda son todo/a ciudadana/o que envio se volvio a comunicar 
ademas del chat o whatsapp observado.

Luego los 3 merge_df se relacionaron al df_casos_final que seria el data frame
final con el que se realizan todos los demas analisis posteriores.  

"""
#Tabla principal

df_casos_final = pd.merge(left=df_casos_limpio1,right=df_encuestas, how='left', left_on='Correo ciudadano/a', right_on='Correo electrónico') #AYUDA MEMORIA - En caso de haber querido traer solo algunas columnas lo detallo al final de parantesis como [['Numero de serie']]

# Tablas auxiliares a vincular en observados

df_enviocorreo = df_casos_limpio1[['Canal','Correo ciudadano/a']]
filtro_soloemail = df_enviocorreo['Canal'] == 'Email Entrante' 
df_enviocorreo = df_enviocorreo[filtro_soloemail]

merged_df1 = pd.merge(left=df_casos_limpio1[df_casos_limpio1['Control de conversaciones'] == 'Observado'],right=df_enviocorreo, how='left', left_on='Correo ciudadano/a', right_on='Correo ciudadano/a')
merged_df1 = merged_df1[['Numero unico de caso','Canal_y']]
merged_df1.rename(columns = {'Canal_y': 'Envio Correo'}, inplace = True)
merged_df1 = merged_df1.replace('Email Entrante','si')

df_envioencuesta = df_encuestas[['Número de serie','Correo electrónico']]
merged_df2 = pd.merge(left=df_casos_limpio1[df_casos_limpio1['Control de conversaciones'] == 'Observado'],right=df_envioencuesta, how='left', left_on='Correo ciudadano/a', right_on='Correo electrónico')
merged_df2 = merged_df2[['Numero unico de caso','Número de serie']]
merged_df2.rename(columns = {'Número de serie': 'Envio encuesta'}, inplace = True)


df_cant_agrupada = df_casos_limpio1.groupby('Correo ciudadano/a').size()
df_cant_agrupada = df_cant_agrupada.apply(lambda x: 'si' if x > 1 else 'NaN')
df_cant_agrupada = df_cant_agrupada .to_frame(name="numbers").reset_index(drop=False)
merged_df3 = pd.merge(left=df_casos_limpio1[df_casos_limpio1['Control de conversaciones'] == 'Observado'],right=df_cant_agrupada, how='left', left_on='Correo ciudadano/a', right_on='Correo ciudadano/a')
merged_df3 = merged_df3[['Numero unico de caso','numbers']]
merged_df3.rename(columns = {'numbers': 'Realizo re-consulta'}, inplace = True)

# Relación o join final con el data frame principal 

df_casos_final = pd.merge(left=df_casos_final,right=merged_df1, how='left', left_on='Numero unico de caso', right_on='Numero unico de caso') 
df_casos_final = pd.merge(left=df_casos_final,right=merged_df2, how='left', left_on='Numero unico de caso', right_on='Numero unico de caso') 
df_casos_final = pd.merge(left=df_casos_final,right=merged_df3, how='left', left_on='Numero unico de caso', right_on='Numero unico de caso') 

""" 10) Verificamos que luego del LEFT JOIN no tengamos filas duplicadas mediante:
 df_casos_final['Numero de caso'].duplicated().sum() """

df_casos_final.drop_duplicates(subset=['Numero unico de caso'],inplace=True)
df_casos_final.rename(columns = {'Submitted Time': 'Fecha de envio'}, inplace = True)

""" Volvemos a verificar y da cero """ 

df_casos_final['Numero unico de caso'].duplicated().sum()

#Se puede descargar,en formato Excel, el dataset final limpiado desde aqui.

df_casos_final.to_excel('df_casos_final.xlsx')

"""##**Exploración de encuestas de satisfacción**"""

#Indica la cantidad de filas y columnas

df_encuestas.shape

#Muestra las primera 10 filas del dataset

df_encuestas.head(10)

#Cuenta todos los nulos segun cada columna

df_encuestas.isna().sum().sort_values(ascending = False)

#Realiza un bucle for donde cuenta el total de veces que aparece un registro de cada columna

for columns in df_encuestas:
   print(df_encuestas[columns].value_counts())

#Describe cada columna de dataset

df_encuestas.info()

"""##**Exploración de reporte de conversaciones unificado con encuestas**"""

#Describe cada columna de dataset

df_casos_final.info()

#Muestra las primera 10 filas del dataset

df_casos_final.head(10)

#Indica la cantidad de filas y columnas

df_casos_final.shape

#Realiza un bucle for donde cuenta el total de veces que aparece un registro de cada columna

for columns in df_casos_final:
   print(df_casos_final[columns].value_counts())


"""##**3. Estadística descriptiva**<a name="id3"></a>

"""

df_casos_final.describe()

filtro = (df_casos_final['Tiempo de espera asignación (en min)']< 60) & (df_casos_final['Tiempo de espera primera respuesta (en min)']< 60) & (df_casos_final['Tiempo de resolución del caso (en min)']< 60)
df_casos_filtrado_estadistica = df_casos_final[filtro]
df_casos_filtrado_estadistica.describe()

"""####**INTERPRETACIÓN:**

Surge la necesidad de filtar un rango de de 0 a 60 minutos. Ya que mediante la 
tabla anterior y los altos valores de los promedios.

Al filtrar los paramatreos de minutos se aseguro un mejor resultado estadistico. Pero se redujo el tamaño de registros a la mitad. Esta primer detección da cuenta de la calidad de lo datos ingresados y de la necesidad de mejorar los aspectos operativos de registros al momentos de dar respuesta o cerrar las conversaciones. 

Respecto a los resultados obtenidos se puede establecer que:

- Los promedios elevados es del tiempo de resolución y de priemra respuesta.En el caso del primero donde se tiene a la persona conversando mucho tiempo. Estando concetrada las cantidades en el segundo y tercer percentil  de mayor duración. Los mismo sucede con el tiempo de primera respuesta en donde la persona no tiene respuesta. Es decir, no se esta teniendo la capacidad de respuesta. 

- Respecto  la desviación estándar, la misma varia segun la variable. Pero la mas cercana a cero (osea un valor bajo agrupado a la su promedio) es la del tiempo de asignación. En lo otros casos la desviación estándar es mayor que su promedio. Por lo tanto significa dispersión. 

En conclusión se manifiesto el problema de valores muy elevados y a su vez datos dispersos por falla de los operadores. Ya el unico caso sin problemas en sus registros es el tiempo de espera, el cual a mitad de año siempre atendia el asistente virtual.

##**4. Estado de situación primer año de implementación**<a name="id4"></a>

##**Evolución anual de conversaciones 2022**
"""

df_graf_linea = df_casos_final[['Fecha de creación' ,'Canal']] 
df_graf_linea.index = df_graf_linea['Fecha de creación'].dt.month
df_graf_linea = df_graf_linea.drop('Fecha de creación', axis='columns')

x_fecha = df_graf_linea.index.unique()
y_cantidad = df_graf_linea.groupby([df_graf_linea.index]).size()
y_cantidad

fig, ax = plt.subplots(figsize=(12, 4))
ax.plot(x_fecha, y_cantidad, label='Cant.de conversaciones')
ax.set_xlabel('Meses')                  
ax.set_ylabel('Cant.de conversaciones')
ax.set_title('Evolución anual de conversaciones 2022')
ax.legend()

"""####**INTERPRETACIÓN:**

El siguente grafico visualiza la evolución historica del primer año de implemetación del CRM de Wise CX para la atención al publico. En este primer año se ve como hubo un crecimiento sostenido y como se genero un pico entre el mes 10 y 12 donde la altama demanda de esos meses se enfoco en este sistema, aceptando su uso para remitir su consulta.

##**Segmentación de cantidad de conversaciones segun canal**
"""

df_graf_circular = df_casos_final[['Fecha de creación' ,'Canal']] 
df_graf_circular.index = df_graf_circular['Canal']
df_graf_circular = df_graf_circular.drop(['Fecha de creación','Canal'], axis='columns')

x = df_graf_circular.index.unique()
y = df_graf_circular.groupby(['Canal']).size()   
y

plt.pie(y, labels=y.index, autopct="%0.1f %%")
plt.axis("equal")
plt.show()

"""####**INTERPRETACIÓN:**

El siguente grafico visualiza como distribuye en 3 segmentos los canales atendidos. En donde predomina el chat en linea y el Whatsapp como cuestion favorable. Ya que estos canales son mas fluidos y permiten una mejor comunicación. Sin embargo, surge la particularidad que Whatsapp se encuentra muy bajo en su porcentaje, siendo este canal el mas practico por tenerlo agendado en el telefono y no tener que ingresar a ninguna pagina. Como tampoco gastar muchos datos. 

En consecuencia se sugerira enfocar la campaña de difusion en alentar el uso de este canal y seguir reduciendo el correo.

##**Cantidad de conversaciones segun tipo de usuario**
"""

df_graf_barra = df_casos_final[['Usuario','Canal']]
x = df_graf_barra.index.unique()
y = df_graf_barra.groupby(['Usuario']).size()   
y

plt.bar(y.index, y)
plt.show()

"""####**INTERPRETACIÓN:**

El siguente grafico visualiza la comparación entre las conversaciones de chat y Whatsapp resueltas por solo el asistente virtual y las que se nesecito la ayuda de un operador. Aunque la necesidad de un operador supera en cantidad al asistente virtual, este igualmente esta mas de la mitad del total de conversaciones. En todo caso se sugire para futuros analisis explorar en que tematicas la información del asistente virtual no alcanzo. Para luego sugerir modificaciones.

En el caso del tipo "Sin asignar" que se dejo al momento de limipiar los datos. Se ve como la cantidad asciende a mas de 2000 conversaciones. Es decir, ya es una de las causas de los valores atipicos encontrados en el momento descriptivo de las estadisticas.

##**Frecuencia de la demanda de conversaciones por horario**
"""

df_graf_histo = df_casos_final[['Fecha de creación' ,'Canal']] 
df_graf_histo.insert(loc = 0 , column = 'Hora', value = df_graf_histo['Fecha de creación'].dt.hour)
df_graf_histo = df_graf_histo.drop('Fecha de creación', axis='columns')
sns.displot(data=df_graf_histo, x="Hora", hue="Canal", multiple="stack")

"""####**INTERPRETACIÓN:**

El siguente grafico visualiza la distribución de frecuencias segun la hora en que ingresan los casos. De este modo se puede realizar una estimación de las necesidades operativas en las franjas horarias de mayor demandas. La cual en los 3 canales se durante el mediodia/tarde dentro del horario oficial de atención.

##**Evolución comparativa entre "primer contacto" y "contacto totales"**
"""

df_casos_final2 = df_casos_final[['Fecha de creación' ,'Correo ciudadano/a']] 
df_casos_final2.index = df_casos_final2['Fecha de creación'].dt.month
df_casos_final2 = df_casos_final2.drop('Fecha de creación', axis='columns')

df_conteo_distintivo = df_casos_final2.groupby('Fecha de creación')['Correo ciudadano/a'].nunique() 
df_conteo_total =df_casos_final2.groupby('Fecha de creación').size() 
df_primera_comunicacion = df_casos_final2.drop_duplicates(subset=['Correo ciudadano/a']).groupby('Fecha de creación')['Correo ciudadano/a'].nunique() 

df_union_series=pd.concat([df_conteo_total,df_primera_comunicacion],axis=1)
df_union_series.rename(columns = {'Correo ciudadano/a': 'Cant.nuevos clientes'}, inplace = True)
df_union_series.rename(columns = {0 : 'Cant.total de conversaciones'}, inplace = True)


df_union_series

sns.lineplot(x = 'Fecha de creación' , y = 'Cant.nuevos clientes', data = df_union_series);
sns.lineplot(x = 'Fecha de creación' , y = 'Cant.total de conversaciones', data = df_union_series);

"""####**INTERPRETACIÓN:**

El siguente grafico visualiza la evolución historica de la cantidad totales de casos (en rojo) y los nuevos usarios (en azul) mes a mes que utilizan el servicio. 

Ambas lineas van en paralelo y tienen las misma tendencia. Lo cual demuestra como la difusion y el uso es creciente. Ademas la brecha entre ambas no amplia. Es decir, no hay altos indices de re consulta que haga que la eprsona se comunico muchas veces porque no se le explico bien. Esta brecha solo se amplia en el mes de diciembre en que hubo una alta demanda.

##**Sumatoria de las variables categoricas de las encuestas**
"""

def graficos_eda_categoricos(cat):
    
    #Calculamos el número de filas que necesitamos
    from math import ceil
    filas = ceil(cat.shape[1] / 2)

    #Definimos el gráfico
    f, ax = plt.subplots(nrows = filas, ncols = 2, figsize = (16, filas * 6))

    #Aplanamos para iterar por el gráfico como si fuera de 1 dimensión en lugar de 2
    ax = ax.flat 

    #Creamos el bucle que va añadiendo gráficos
    for cada, variable in enumerate(cat):
        cat[variable].value_counts().plot.barh(ax = ax[cada])
        ax[cada].set_title(variable, fontsize = 12, fontweight = "bold")
        ax[cada].tick_params(labelsize = 12)

grafico_categorias_encuestas = df_encuestas.drop(columns =['Número de serie','Submitted Time','Correo electrónico','¿Tenés otros comentarios, sugerencias u observaciones sobre el servicio recibido?'],axis=1)

graficos_eda_categoricos(grafico_categorias_encuestas.select_dtypes('O'))

"""####**INTERPRETACIÓN:**

En esta visualización se muestran todas las cantidades de los resultados de cada variable categorica de las encuestas enviadas luego de cada conversación. En lineas general las respuestas son positivas. El unico problema a resolver es el universo encuestado. Es decir, la cantidad de encuestas solo son 1000, mientras que el total de casos supera los 20.000. Por lo tanto las encuestas no garantizan ser una retroalimentación de un buen servicio. Por lo tanto, para futuros analisis se establecera un indicador de re-consulta o si la persona tuvo que comunicarse muchas veces para resolver su consulta. Ya que al ser un canal de atención primaria, no tenemos consultas frecuentes de una misma persona. Estas luego resuelven su consulta en el area tecnica o oficina en cuestion.

##**5. Calidad del servicio segun observaciones**<a name="id5"></a>
"""

graf_y = df_casos_final['Control de conversaciones']
graf_x = df_casos_final['Canal']
sns.countplot(x=graf_y, hue = graf_x)

df_recuperados = df_casos_final[['Control de conversaciones','Envio Correo','Envio encuesta','Realizo re-consulta']]
filtro_observado2 = df_recuperados['Control de conversaciones'] == 'Observado'
df_recuperados  = df_recuperados[filtro_observado2]
df_recuperados = df_recuperados.replace('NaN',"no")


pd.crosstab(index=df_recuperados['Control de conversaciones'],
            columns=df_recuperados['Realizo re-consulta'], margins=True)

agrupacion2 = df_recuperados.groupby(['Control de conversaciones']).agg({'Envio Correo': 'count', 'Envio encuesta': 'count','Control de conversaciones':'count'})
agrupacion2

graf_barra_tipo = df_casos_final[['Tipo','Control de conversaciones','Canal']]
lista_excluirgrafico = ['NO RECIBIDO','CHAT SUSPENDIDO','NO INFORMA TEMA']
filtro_email4 = graf_barra_tipo ['Canal'] != 'Email Entrante' 
graf_barra_tipo  = graf_barra_tipo[filtro_email4] 
graf_barra_tipo = graf_barra_tipo [~graf_barra_tipo ['Tipo'].isin(lista_excluirgrafico)]


sns.countplot(y= graf_barra_tipo['Tipo'], hue=graf_barra_tipo['Control de conversaciones'])

"""####**Interpretación**:

Nuestra pregunta o hipotesis fundamental era poder determinar si hubo una demanda real de la necesidad de implemetar este servicio. Segun se pudo ver esto se confirmo. Ahora bien, respecto a la calidad del mismo, segun lo analizado hasta aqui se comprueba en primera instancia que la mitad de las conservaciones por chat y WhatsApp fuero observadas. Es decir, la persona no obtuvo la respuesta o se fue ante una respuesta incorrecta. 

En consecuencia, ante la alta cantidad de observados es necesario monitorear los casos recuperados. Es decir,cuantos de los casos observados volvieron  y se le pudo dar respuesta. En este sentido de los 9107 casos observados, que son la mitad de las conversaciones atendidas por operadores, el mas de la mitad (5636 de casos) de los mismos se volvio a comunicar, envio encuesta (la cual si fue negativa se responde e indaga) o envio correo a responde@senasa.gob.ar para que le respondan.  

Finalmente se detecta como no conformidad grave que este error de observación por chat suspedido o abandonado origina tambien un error en la tipificación de conversaciones. Las cuales en su amplia mayoria estan como "SIN TIPO" a pesar que se trato de encontrar tipificación mediante metodos de texto o string. De este modo ante la falta del dato no se puede analizar si el origen de la observación esta relacionado a la tipificación tematica de la conversación. 

En conclusión, para analizar las observaciones se procedera a utilizar variables cuantitativas y no categoricas ante la falta de datos.

##**6. Analisis cuantitativo de las observaciones**<a name="id6"></a>

##**Analisis de los observados segun el tiempo de respuesta y la cantidad de casos**
"""

filtro = (df_casos_final['Tiempo de espera primera respuesta (en min)']< 60) & (df_casos_final['Tiempo de espera primera respuesta (en min)']>10)
df_graf_dispersion2 = df_casos_final[filtro]

sns.scatterplot(data=df_graf_dispersion2, y='Tiempo de espera primera respuesta (en min)', x=df_graf_dispersion2.index)

sns.catplot(x = 'Tiempo de espera primera respuesta (en min)', data = df_graf_dispersion2, kind = "box", aspect = 1.5)

"""####**INTERPRETACIÓN:**

En el siguente grafico se visualiza la distribución del tiempo de primera respuesta, como a su vez la relación si ante mas casos mas se tarda en dar primera respuesta. Aqui se puede ver como el aumento de la demanda genero mas espera en la ciudadania.

En primera instancia el boxplot indica como la media entre el primer cuartil y el tercero esta entre 15 y 30 minutos. Lo cual, ya hace referencia a un mal servicio ante la alta espera.

Ante la espera la persona abandona la conversación y si utilizo el canal de chat en linea ya no permite continuar la conversación. Caso contrario sucede con el whatsapp. Este se refleja en el grafico de barras analizado anteriormente.

##**Analisis de los observados segun cantidad de mensajes, tiempo de resolución y casos observados por abandono**
"""

sns.scatterplot(x ='Cantidad de palabras por conversación' , y = df_analisis_obs4.index, hue = 'Control de conversaciones',data = df_analisis_obs4)

"""####**INTERPRETACIÓN:**

A modo de sintesis de lo analizado anteriormente, se vio como hay muchos casos observados por abandono por demora del agente en dar su primera respuesta. Esta cantidad de casos no es parte del total, pero si un valor siginificativo en el canal de chat en linea (el Whatsapp permite comunicación constante y el correo no hay posibilidad de desconexción). 

En estos otros 2 graficos se plantea relacionar el aumento de demanda de casos con la cantidad de mensajes y de tiempo de resolución. Todo esto segmentado segun observación o no. Un detalle a descatar es que la distribución de los puntos muestran una alta cantidad de observados en conversaciones que superaron los 10 mensajes. Es decir, no solo hay un problema de espera, sino que no se esta siendo asertivo en la indagación a la persona que se contacta y no le sirve el bot y pide hablar con un operador. Es decir, se debe analizar los tipos de conversaciones para gestionar el conocimiento. Sin embargo al ver los datos hay varios sin tipficar a mejorar la limpieza.

##**Analisis de los observados segun correlación Pearson**
"""

df_analisis_obs = df_casos_final[['Canal','Cantidad de palabras por conversación','Tiempo de resolución del caso (en min)','Tiempo de espera primera respuesta (en min)','Control de conversaciones']]
filtro_espera = (df_analisis_obs['Tiempo de espera primera respuesta (en min)']< 60) & (df_casos_final['Tiempo de espera primera respuesta (en min)']>1)
filtro_resolucion = (df_analisis_obs['Tiempo de resolución del caso (en min)']< 60) & (df_casos_final['Tiempo de resolución del caso (en min)']>1)
filtro_email3 = df_analisis_obs['Canal'] != 'Email Entrante' 
df_analisis_obs2 = df_analisis_obs[filtro_email3] 
df_analisis_obs3 = df_analisis_obs[filtro_espera]
df_analisis_obs4= df_analisis_obs2[filtro_resolucion]

df_analisis_obs4

graf_correlacion = df_casos_final[['Canal','Cantidad de palabras por conversación','Tiempo de espera primera respuesta (en min)','Tiempo de resolución del caso (en min)','Tiempo de espera asignación (en min)','Control de conversaciones']]
filtro_observado = graf_correlacion['Control de conversaciones'] == 'Observado'
graf_correlacion2 = graf_correlacion[filtro_observado]
filtro_email5 = graf_correlacion ['Canal'] != 'Email Entrante' 
filtro_tiempo = (graf_correlacion['Tiempo de resolución del caso (en min)']< 60) & (graf_correlacion['Tiempo de resolución del caso (en min)']>1)
graf_correlacion = graf_correlacion[filtro_tiempo]
graf_correlacion  = graf_correlacion[filtro_email5] 
graf_correlacion2.corr(method='pearson')

plt.matshow(graf_correlacion2.corr(method='pearson'))

"""####**INTERPRETACIÓN:**

El ultimo analisis cuantitativo de las observaciones se realiza mediante un coeficiente de correlación de Pearson, cuya prueba permite descubrir una relación directa/lineal entre dos variables continuas. Es decir, cual es la covarianza en conjunto de 2 variables.

El resultado de los graficos seran intervalos [-1,1], estableciendo el signo el sentido de la relación, y la interpretación de cada resultado es el siguiente:

- Si r = 1: Correlación positiva perfecta. El índice refleja la dependencia total entre ambas dos variables, la que se denomina relación directa: cuando una de las variables aumenta, la otra variable aumenta en proporción constante.

- Si 0 < y < 1: Refleja que se da una correlación positiva. Si r = 0: En este caso no hay una relación lineal. Aunque no significa que las variables sean independientes, ya que puede haber relaciones no lineales entre ambas variables.

- Si -1 < y < 0: Indica que existe una correlación negativa.

- Si r = -1: Indica una correlación negativa perfecta y una dependencia total entre ambas variables lo que se conoce como “relación inversa”, que es cuando una de las variables aumenta, la otra variable en cambio disminuye en proporción constante.

En el grafico generado no se visualizan corrlaciones lineales fuertes. El mas alto es el de 0,10 entre espera de asignación y cantidad de palabras.

##**7. Auditoria de casos**<a name="id7"></a>

Luego de finalizar el estado de situación de la demanda, la calidad de servicio ofrecida y el analisis de los motivos de las observaciones encontradas. Se procede a utilizar algoritmos de Machine Learning que permitan planificar auditorias sobre las conversaciones diarias. Es decir, que una persona tome como referencia los resultados de estos apredizajes supervizados y le ayude a determinar que casos auditar y no realizar un muestreo azaroso.

##**7.1 Uso de Clustering kmeans para clasificación**
"""

df_casos_final_kmeans = df_casos_final[['Canal','Cantidad de palabras por conversación','Tiempo de resolución del caso (en min)','Tiempo de espera primera respuesta (en min)','Control de conversaciones']]
filtro_email5 = df_casos_final_kmeans ['Canal'] != 'Email Entrante' 
df_casos_final_kmeans  = df_casos_final_kmeans[filtro_email5] 
filtro_tiempo = (df_casos_final_kmeans['Tiempo de resolución del caso (en min)']< 60) & (df_casos_final_kmeans['Tiempo de resolución del caso (en min)']>1)
df_casos_final_kmeans = df_casos_final_kmeans[filtro_tiempo]
filtro_tiempo2 = (df_casos_final_kmeans['Tiempo de espera primera respuesta (en min)']< 60)
df_casos_final_kmeans = df_casos_final_kmeans[filtro_tiempo2]
df_casos_final_kmeans = df_casos_final_kmeans.drop(columns = ['Canal'], axis=1)

# Pasamos el las categorias a dummies

df_kmeans=pd.get_dummies(df_casos_final_kmeans, columns=['Control de conversaciones'])

# Normalizamos las columnas numericas
df_kmeans["Cantidad de palabras por conversación"] = (df_kmeans["Cantidad de palabras por conversación"] - df_kmeans["Cantidad de palabras por conversación"].min()) / (df_kmeans["Cantidad de palabras por conversación"].max() - df_kmeans["Cantidad de palabras por conversación"].min())
df_kmeans["Tiempo de resolución del caso (en min)"] = (df_kmeans["Tiempo de resolución del caso (en min)"] - df_kmeans["Tiempo de resolución del caso (en min)"].min()) / (df_kmeans["Tiempo de resolución del caso (en min)"].max() - df_kmeans["Tiempo de resolución del caso (en min)"].min())
df_kmeans["Tiempo de espera primera respuesta (en min)"] = (df_kmeans["Tiempo de espera primera respuesta (en min)"] - df_kmeans["Tiempo de espera primera respuesta (en min)"].min()) / (df_kmeans["Tiempo de espera primera respuesta (en min)"].max() - df_kmeans["Tiempo de espera primera respuesta (en min)"].min())

df_kmeans

"""####**Clustering: Cant. palabras - Tiempo resolución**"""

c1 = "Cantidad de palabras por conversación"
c2 = "Tiempo de resolución del caso (en min)"


inercias = []
for n in range(1, 11):
    km = KMeans(n_clusters=n, init='k-means++', random_state=42)
    km.fit(df_kmeans[[c1, c2]])
    inercias.append(km.inertia_)

inercias
# Inercia: Suma de las distancias al cuadrado de los puntos a su centroide más cercano

# Graficamos la curva de inercias para ver el codo
plt.figure(1, figsize=(10, 5))
plt.plot(range(1, 11) , inercias , 'o')
plt.plot(range(1, 11) , inercias , '-' , alpha=0.5)
plt.xlabel('Cantidad de clusters')
plt.ylabel('Inercias')
plt.show()

# Tomamos k=3 y entrenamos
k = 3
km = KMeans(n_clusters=k, init='k-means++', random_state=42)
km.fit(df_kmeans[[c1, c2]])

labels = km.labels_
centroids = km.cluster_centers_

# Graficamos
plt.figure(1, figsize=(10, 5))
plt.scatter(x=c1, y=c2, data=df_kmeans[[c1, c2]], c=labels, s=100)
plt.scatter(x=centroids[:, 0] , y=centroids[:, 1], s=120 , c="red", alpha=0.5)
plt.xlabel(c1)
plt.ylabel(c2)
plt.show()

#agregar al df sin normalizar
df_casos_final_kmeans['Cant. palabras - Tiempo resolución']= labels

"""####**Clustering: Cant. palabras - Tiempo Asignación**"""

c1 = "Cantidad de palabras por conversación"
c3 = "Tiempo de espera primera respuesta (en min)"


inercias = []
for n in range(1, 11):
    km = KMeans(n_clusters=n, init='k-means++', random_state=42)
    km.fit(df_kmeans[[c1, c3]])
    inercias.append(km.inertia_)

inercias
# Inercia: Suma de las distancias al cuadrado de los puntos a su centroide más cercano

# Graficamos la curva de inercias para ver el codo
plt.figure(1, figsize=(10, 5))
plt.plot(range(1, 11) , inercias , 'o')
plt.plot(range(1, 11) , inercias , '-' , alpha=0.5)
plt.xlabel('Cantidad de clusters')
plt.ylabel('Inercias')
plt.show()

# Tomamos k=3 y entrenamos
k = 3
km = KMeans(n_clusters=k, init='k-means++', random_state=42)
km.fit(df_kmeans[[c1, c3]])

labels2 = km.labels_
centroids = km.cluster_centers_

# Graficamos
plt.figure(1, figsize=(10, 5))
plt.scatter(x=c1, y=c3, data=df_kmeans[[c1, c3]], c=labels2, s=100)
plt.scatter(x=centroids[:, 0] , y=centroids[:, 1], s=120 , c="red", alpha=0.5)
plt.xlabel(c1)
plt.ylabel(c3)
plt.show()

df_casos_final_kmeans['Cant. palabras - Tiempo Asignación']= labels2

"""####**Clustering: Tiempo de resolución - Tiempo primera respuesta**"""

c2 = "Tiempo de resolución del caso (en min)"
c3 = "Tiempo de espera primera respuesta (en min)"


inercias = []
for n in range(1, 11):
    km = KMeans(n_clusters=n, init='k-means++', random_state=42)
    km.fit(df_kmeans[[c2, c3]])
    inercias.append(km.inertia_)

inercias
# Inercia: Suma de las distancias al cuadrado de los puntos a su centroide más cercano

# Graficamos la curva de inercias para ver el codo
plt.figure(1, figsize=(10, 5))
plt.plot(range(1, 11) , inercias , 'o')
plt.plot(range(1, 11) , inercias , '-' , alpha=0.5)
plt.xlabel('Cantidad de clusters')
plt.ylabel('Inercias')
plt.show()

# Tomamos k=3 y entrenamos
k = 3
km = KMeans(n_clusters=k, init='k-means++', random_state=42)
km.fit(df_kmeans[[c2, c3]])

labels3 = km.labels_
centroids = km.cluster_centers_

# Graficamos
plt.figure(1, figsize=(10, 5))
plt.scatter(x=c2, y=c3, data=df_kmeans[[c2, c3]], c=labels3, s=100)
plt.scatter(x=centroids[:, 0] , y=centroids[:, 1], s=120 , c="red", alpha=0.5)
plt.xlabel(c2)
plt.ylabel(c3)
plt.show()

"""##**7.1.1 Uso de Clustering kmeans para clasificación**"""

#Tabla final con los 3 kmeas realizados

df_casos_final_kmeans['Tiempo de resolución - Tiempo Asignación']= labels3
df_casos_final_kmeans

#Agrupación de niveles de kmeas clasficados segun el criterio de Tiempo de resolución - Tiempo Asignación

agrupacion_kmeas3 = df_casos_final_kmeans.groupby(['Tiempo de resolución - Tiempo Asignación','Control de conversaciones']).agg({'Tiempo de resolución del caso (en min)': 'mean' ,'Tiempo de espera primera respuesta (en min)': 'mean','Control de conversaciones':'count' })
agrupacion_kmeas3

#Agrupación de niveles de kmeas clasficados segun el criterio de Cant. palabras - Tiempo resolución

agrupacion_kmeas1 = df_casos_final_kmeans.groupby(['Cant. palabras - Tiempo resolución','Control de conversaciones']).agg({'Cantidad de palabras por conversación': 'mean', 'Tiempo de resolución del caso (en min)': 'mean' ,'Control de conversaciones':'count'})
agrupacion_kmeas1

#Agrupación de niveles de kmeas clasficados segun el criterio de Cant. palabras - Tiempo Asignación

agrupacion_kmeas2 = df_casos_final_kmeans.groupby(['Cant. palabras - Tiempo Asignación','Control de conversaciones']).agg({'Cantidad de palabras por conversación': 'mean','Tiempo de espera primera respuesta (en min)': 'mean','Control de conversaciones':'count' })
agrupacion_kmeas2

"""####**INTERPRETACIÓN:**

El uso de Clustering Kmeans nos permitio identificar grupos segun las variables cuantitativas que poseemos. Estas variables de tiempo se filtraton segun valores normales de una conversación que en el dia cotidiano no dura mas de 1 hora. De este modo se quitaron los errores operativos. Por ejemplo, dejar un caso todo el dia sin cerrar hasta que pasadas las 24 hs se cierra automaticamente. 

De los grupos identificados **tomamos los que esten discrimados como observados** y tomamos sus valores promedios normales segun el grupo, para seleccionar que conversaciones auditar. Obsivamente si la conversaciones tiene valores outlier fuera de estas condiciones normales de tiempo, se procede automaticamente a su revision, como tambien si no tienen la tipificación como se dijo anteriormente. Pero, en caso de la gran mayoria, estos criterios de segmentación nos permiten reducir factres de elccion azarosa. 

A su vez, se sugerie siguendo el analisis realizado en los graficos de dispersión, tener en cuenta las cuestiones de cantidad de palbras y tiempo de primera respuesta.

##**7.2 Regresión Lineal de observados** 

A continuación se utiliza la regresión lineal multiple para indicar la tendencia que poseen los datos. Es decir, la relación entre una variable  dependiente y varias variables explicativas/explicativa. En este caso la variable dependiente a predecir son la cantidad de casos observados y la independiente/explicativa son la cantidad de mensajes y tiempos. 

El objetivo de esto tener una herramienta predictiva para saber si a ciertos valores promedios que se repiten que cantidad de observados se espera tener y tratar de mejorar el servicio para evitarlo preventivamente.
"""

df_casos_final_regresion = df_casos_final[['Canal','Tipo','Cantidad de palabras por conversación','Tiempo de resolución del caso (en min)','Tiempo de espera primera respuesta (en min)','Control de conversaciones']]
filtro_email5 = df_casos_final_regresion ['Canal'] != 'Email Entrante' 
df_casos_final_regresion  = df_casos_final_regresion[filtro_email5] 
filtro_tiempo = (df_casos_final_regresion['Tiempo de resolución del caso (en min)']< 60) & (df_casos_final_regresion['Tiempo de resolución del caso (en min)']>1)
df_casos_final_regresion = df_casos_final_regresion[filtro_tiempo]
filtro_tiempo2 = (df_casos_final_regresion['Tiempo de espera primera respuesta (en min)']< 60)
df_casos_final_regresion = df_casos_final_regresion[filtro_tiempo2]
filtro_observado = df_casos_final_regresion['Control de conversaciones'] == 'Observado'
df_casos_final_regresion  = df_casos_final_regresion[filtro_observado]
df_casos_final_regresion = df_casos_final_regresion.drop(columns = ['Canal','Tipo','Control de conversaciones'], axis=1)
df_casos_final_regresion.reset_index(drop=True, inplace=True) 
df_casos_final_regresion

x = df_casos_final_regresion[['Cantidad de palabras por conversación','Tiempo de resolución del caso (en min)','Tiempo de espera primera respuesta (en min)']]
y = df_casos_final_regresion.index


regr = linear_model.LinearRegression()
regr.fit(x, y)

y_pred = regr.predict(x)

# Los coeficientes
print('Coefficientes: \n', regr.coef_)
# Error cuadrático medio
print("Error cuadratico medio: %.2f" % mean_squared_error(y, y_pred))
# Evaluamos el puntaje de varianza (siendo 1.0 el mejor posible)
print('Varianza: %.2f' % r2_score(y, y_pred))

"""**Metricas del modelo:** 

- El Error Cuadrático Medio es grande. Este surge la diferencia cuadrada entre las predicciones y el objetivo y luego promedia esos valoresde Es decir si esta alejado de 0, peor es el modelo.

- En el caso de la varianza esta cercana a 1. Ya que esta a la mitad.

"""

y_pred = regr.predict(x)

sns.scatterplot(x=y_pred, y=y)
sns.regplot(x=y_pred, y=y)
plt.xlabel('Predicciones')
plt.ylabel('Valores reales')
plt.show()

"""El gráfico muestra una línea diagonal que representa la línea de regresión. Si los puntos están cerca de la línea, significa que el modelo se ajusta bien a los datos. Si los puntos están dispersos, significa que el modelo no se ajusta bien. En este caso hay algunos puntos alejados de la linea, lo cual demuestra lo explicado en el Error Cuadrático Medio.

####**Predictor de observados**
"""

cant_palabras, tiempo_resolucion, tiempo_espera = map(int, input('coloque entre espacios 3 valores promedios del mes o trimestre vencido (1- cantidad palabras,2-tiempo en minutos de resolucion,3- tiempo en minutos de espera) \n').strip().split())
print(f"fewe{regr.predict([[cant_palabras, tiempo_resolucion, tiempo_espera]])}")

"""##**8. Resultados finales y propuesta**<a name="id8"></a>

Hemos llegado al final de nuestra evaluación y a modo sintesis se indican los siguentes hallazagos: 

- La implementación del nuevo servicio de atención tuvo una buena recepeción y genero demanda externa por parte de la ciudadania. 

- Las encuestas de satisfacción, aunque sean una muestra pequeña reflejan una buena devolución. No es el caso del control de calidad de conservaciones observadas. 

- Se deberan implementar indicadores para controlar la calidad de las observaciones y alentar la difusión del asistente virtual. 

- Se debera estadarizar los aspectos operativos de los tiempos, en caso que los valores atipicos surgan de errores humanos. Por ejemplo, cerrar un caso tarde aunque ya este resuelto o no usar plantillas para dar una primera respuesta rapido. 

- Se debera estadarizar los aspectos operativos de las tipificaciones, para conocer mejor que cnsultas frecuentes se realizan y asi poder indigar la estadistica por tipo de tema consultado y se relacionara eso con los valores de tiempo, junto a la cantidad de mensajes. 

A modo de sugerencia para realizar un monitoreo de la calidad y de la demanda del servicio. Se establece la siguente tabla de mediciones. 

|Indicador de Seguimiento / Mediciones| |
|:----|:----|
|Porcentaje de encuestas  Encontró la información|Se contabilizan las respuestas seleccionadas en la encuesta de atención enviada|
|Porcentaje de encuestas  sobre tiempo de atención satisfactorio|Se contabilizan las respuestas seleccionadas en la encuesta de atención enviada|
|Porcentaje de encuesta  sobre atención satisfactoria|Se contabilizan las respuestas seleccionadas en la encuesta de atención enviada|
|Cantidad de atenciones realizadas|Se contabilizan la cantidad de atenciones realizadas por los distintitos canales|
|Porcentaje de eficacia del asistente virtual|Cantidad de personas que se comunicaron con el asistente virtual y no volvieron a consultar
|Porcentaje de conversaciones observadas recuperadas|Cantidad de personas que no pudieron comunicarse o abandonaron por no encontrar la información y volvieron a comunicarse por otros medios
|Promedio de conversaciones netas|Cuantas conversaciones reales se tiene por dia descartando las que tiene el asistente virtual y las observadas
|Porcentaje de conversaciones con errores operativos|Cuantas conversaciones no se cerro a tiempo o no se cargo el tipo de tema.|


"""
